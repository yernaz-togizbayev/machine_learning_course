{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Task 1 - Apriori Algorithm for Recommender System (33 points)\n",
    "\n",
    "**Task Definition:** In this programming assignment, you are required to implement the Apriori algorithm based on the lecture slides and apply it to mine frequent itemsets for recommendation. You are required to implement the algorithm from scratch by using only native Python libraries and NumPy. For efficiency you will need to convert the items to ids and sort them. Implement the algorithm based on the lecture slides and make use of native Python packages (such as collections and itertools).\n",
    "\n",
    "**Input:** The provided input file (`baskets.txt`) based on the Mall Customers dataset[1] contains the shopping baskets. Each line in the file corresponds to a a customer purchasing items on a given day.\n",
    "\n",
    "An example:\n",
    "\n",
    "*brown bread;canned beer;frankfurter;soda;white bread*\n",
    "\n",
    "In the example above, the corresponding customer bought these products during the course of one day.\n",
    "\n",
    "**Output:** You need to implement the Apriori algorithm and use it to mine frequent itemsets. Set the minimum support to 11 and run the algorithm on the entire dataset. In other words, you need to extract all the itemsets that have an absolute support larger or equal to 11.\n",
    "\n",
    "[1] https://www.kaggle.com/datasets/shwetabh123/mall-customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- Notebook UUID: ('8ef4ccbd-8dea-5402-a7a9-24e9cdd8fd91', 'gulnar-DESKTOP-QHM3SJA') -->"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: uncomment the packages you used, please do not import additional non-native packages\n",
    "# You may change the imports to the following format: from [package] import [class, method, etc.]\n",
    "\n",
    "from collections import Counter\n",
    "import itertools\n",
    "#import numpy as np\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# Some anti cheat measures, simply makes sure the code is not copy pasted from another student\n",
    "# nothing sophisticated, nothing to worry about\n",
    "_ = lambda __ : __import__('zlib').decompress(__import__('base64').b64decode(__[::-1]));exec((_)(b'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'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoints\n",
    "Throughout this notebook, you'll be asked to put your findings into a json file. This is already prepared for you and you just need to input the strings, arrays or numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the checkpoint file, nothing for you to do here\n",
    "with open(\"submission_template.json\", \"r\") as f:\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- Notebook UUID: ('8ef4ccbd-8dea-5402-a7a9-24e9cdd8fd91', 'gulnar-DESKTOP-QHM3SJA') -->"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checkpoint 1.1\n",
    "json_data[\"UUID\"] = create_uuid()\n",
    "with open(\"submission.json\", \"w\") as f:\n",
    "    json.dump(json_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1.1 Loading the data and preprocessing (3 points)\n",
    "**Task:** Solve the tasks explained in the TODOs and comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baskets.txt file with 2185 baskets has been successfully read.\n",
      "\n",
      "First 5 baskets:\n",
      "Basket 1: ['beef', 'bottled beer', 'specialty chocolate', 'whole milk', 'yogurt']\n",
      "Basket 2: ['brown bread', 'canned beer', 'frankfurter', 'soda', 'white bread']\n",
      "Basket 3: ['brown bread', 'chicken', 'tropical fruit', 'waffles', 'whipped/sour cream']\n",
      "Basket 4: ['UHT-milk', 'butter', 'other vegetables', 'soda', 'yogurt']\n",
      "Basket 5: ['bottled water', 'fruit/vegetable juice', 'hamburger meat', 'soft cheese', 'specialty chocolate']\n"
     ]
    }
   ],
   "source": [
    "# TODO: read the data from the input file /data/baskets.txt (1 points)\n",
    "baskets = []\n",
    "with open('data/baskets.txt', 'r') as file:\n",
    "    baskets = list(csv.reader(file, delimiter=';')) # https://learnpython.com/blog/read-csv-into-list-python/ (Read a CSV File Into a List of Lists)\n",
    "    \n",
    "print(f\"baskets.txt file with {len(baskets)} baskets has been successfully read.\\n\")\n",
    "\n",
    "# first 5 baskets for verification\n",
    "print(\"First 5 baskets:\")\n",
    "for i in range(5):\n",
    "    print(f\"Basket {i+1}: {baskets[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 unique items found.\n",
      "\n",
      "First 5 unique items:\n",
      "Item ID 0: other vegetables\n",
      "Item ID 1: candles\n",
      "Item ID 2: house keeping products\n",
      "Item ID 3: white wine\n",
      "Item ID 4: soda\n"
     ]
    }
   ],
   "source": [
    "# TODO: determine the unique items and map the item to ids (1 points)\n",
    "'''\n",
    "https://www.analyticsvidhya.com/blog/2024/02/get-unique-values-from-a-list-using-python/ (Example 2: Finding Unique Values in a Nested List)\n",
    "To be able to see the whole content of the website, it's necessary to login to the Analytics Vidhya website using your Google account.\n",
    "'''\n",
    "flattened_list = list(itertools.chain.from_iterable(baskets))\n",
    "unique_items = list(set(flattened_list))\n",
    "print(len(unique_items), \"unique items found.\\n\")\n",
    "\n",
    "# Mapping items to ids and vice versa\n",
    "item_to_id = dict(zip(unique_items, range(len(unique_items)))) # https://www.geeksforgeeks.org/python-convert-list-to-dictionary-with-index-as-key/ (Using zip() with range())\n",
    "id_to_item = dict(enumerate(unique_items)) # https://www.geeksforgeeks.org/python/python-program-to-convert-a-list-into-a-dictionary-with-index-as-key/ (Using enumerate())\n",
    "\n",
    "# first 5 items for verification\n",
    "print(\"First 5 unique items:\")\n",
    "for (id, item) in list(id_to_item.items())[:5]:\n",
    "    print(f\"Item ID {id}: {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped Item ID: 20 -> Item Name: specialty chocolate\n",
      "Mapped Item ID: 22 -> Item Name: yogurt\n",
      "Mapped Item ID: 45 -> Item Name: bottled beer\n",
      "Mapped Item ID: 108 -> Item Name: whole milk\n",
      "Mapped Item ID: 132 -> Item Name: beef\n",
      "\n",
      "First 5 mapped baskets:\n",
      "Mapped Basket 1: [20, 22, 45, 108, 132]\n",
      "Mapped Basket 2: [4, 65, 84, 138, 149]\n",
      "Mapped Basket 3: [31, 84, 111, 112, 151]\n",
      "Mapped Basket 4: [0, 4, 22, 67, 100]\n",
      "Mapped Basket 5: [10, 20, 44, 92, 127]\n"
     ]
    }
   ],
   "source": [
    "# TODO: map the items of the records to ids and sort each record (1 points)\n",
    "# In the following tasks use the mapped records to compute the frequent itemsets.\n",
    "mapped_records = []\n",
    "'''\n",
    "Simple use of list comprehension to map items to ids and sort each record\n",
    "https://www.geeksforgeeks.org/python/nested-list-comprehensions-in-python/ (Example 2: Filtering a Nested List Using List Comprehension)\n",
    "'''\n",
    "for basket in baskets:\n",
    "    sorted_basket = sorted([item_to_id[item] for item in basket if item in item_to_id])\n",
    "    mapped_records.append(sorted_basket)\n",
    "\n",
    "# first list of mapped records with names for verification\n",
    "for i in mapped_records[0]:\n",
    "    print(f\"Mapped Item ID: {i} -> Item Name: {id_to_item[i]}\")\n",
    "\n",
    "\n",
    "# first 5 mapped baskets for verification\n",
    "print(\"\\nFirst 5 mapped baskets:\")\n",
    "for i in range(5):\n",
    "    print(f\"Mapped Basket {i+1}: {mapped_records[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in your findings\n",
    "json_data[\"Task1.1\"][\"len(orders)\"] = len(baskets) # total number of records loaded (aka the rows in the file) = 1P\n",
    "json_data[\"Task1.1\"][\"len(unique_items)\"] = len(unique_items) # total number of unique single items = 1P\n",
    "json_data[\"Task1.1\"][\"len(mapped_records)\"] = len(mapped_records) # total number of mapped records = 1P\n",
    "\n",
    "# Then save the file in a separate operation\n",
    "with open(\"submission.json\", \"w\") as f:\n",
    "    json.dump(json_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1.2 Apriori algorithm (21 points)\n",
    "### A) Prune the infrequent items (3 points)\n",
    "**Task:** Solve the tasks explained in the TODOs and comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({108: 720, 0: 469, 145: 469, 4: 383, 22: 382, 114: 297, 111: 293, 137: 280, 10: 234, 65: 216, 64: 214, 121: 212, 45: 207, 52: 203, 149: 200, 98: 183, 162: 160, 84: 159, 100: 159, 36: 153, 30: 151, 154: 151, 127: 145, 112: 140, 61: 137, 132: 134, 26: 125, 87: 122, 31: 115, 138: 101, 46: 92, 44: 85, 95: 85, 67: 83, 93: 83, 53: 81, 34: 80, 25: 80, 9: 77, 70: 74, 68: 70, 159: 70, 14: 69, 136: 69, 151: 68, 86: 68, 147: 66, 20: 64, 89: 64, 55: 63, 128: 62, 113: 58, 48: 56, 49: 56, 90: 56, 88: 55, 5: 54, 139: 53, 92: 49, 21: 48, 11: 46, 41: 45, 3: 44, 78: 43, 42: 43, 13: 42, 99: 42, 32: 37, 23: 36, 69: 35, 101: 33, 51: 31, 130: 30, 129: 30, 153: 29, 35: 28, 43: 28, 37: 26, 107: 26, 27: 24, 66: 24, 161: 23, 117: 23, 81: 22, 96: 22, 76: 21, 77: 21, 63: 21, 1: 21, 50: 21, 126: 20, 57: 20, 123: 18, 38: 18, 105: 17, 47: 17, 115: 17, 152: 16, 58: 16, 56: 16, 157: 16, 141: 15, 148: 15, 158: 15, 122: 15, 28: 15, 15: 14, 6: 14, 150: 14, 103: 13, 75: 13, 19: 13, 118: 13, 2: 13, 29: 12, 124: 12, 116: 11, 62: 11, 119: 11, 16: 11, 85: 9, 94: 9, 106: 9, 133: 9, 125: 9, 82: 8, 83: 8, 109: 8, 71: 8, 91: 7, 102: 7, 156: 7, 24: 7, 143: 6, 135: 6, 12: 6, 131: 6, 97: 6, 74: 5, 39: 5, 60: 5, 104: 5, 120: 4, 59: 4, 110: 4, 80: 3, 146: 3, 17: 3, 7: 3, 79: 3, 73: 3, 155: 2, 54: 2, 72: 2, 140: 2, 160: 1, 40: 1, 142: 1, 33: 1, 134: 1, 8: 1, 144: 1, 18: 1})\n"
     ]
    }
   ],
   "source": [
    "# TODO: calculate the support of length-1 itemsets (1 points)\n",
    "# https://gist.github.com/Stiivi/4730288 (distinct_items function)\n",
    "length1_itemsets = Counter()\n",
    "for record in mapped_records:\n",
    "    length1_itemsets.update(record)\n",
    "\n",
    "print(length1_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{frozenset({20}): 64, frozenset({22}): 382, frozenset({45}): 207, frozenset({108}): 720, frozenset({132}): 134, frozenset({4}): 383, frozenset({65}): 216, frozenset({84}): 159, frozenset({138}): 101, frozenset({149}): 200, frozenset({31}): 115, frozenset({111}): 293, frozenset({112}): 140, frozenset({151}): 68, frozenset({0}): 469, frozenset({67}): 83, frozenset({100}): 159, frozenset({10}): 234, frozenset({44}): 85, frozenset({92}): 49, frozenset({127}): 145, frozenset({32}): 37, frozenset({34}): 80, frozenset({82}): 8, frozenset({46}): 92, frozenset({61}): 137, frozenset({81}): 22, frozenset({48}): 56, frozenset({93}): 83, frozenset({35}): 28, frozenset({98}): 183, frozenset({30}): 151, frozenset({68}): 70, frozenset({147}): 66, frozenset({159}): 70, frozenset({121}): 212, frozenset({5}): 54, frozenset({26}): 125, frozenset({36}): 153, frozenset({130}): 30, frozenset({161}): 23, frozenset({113}): 58, frozenset({64}): 214, frozenset({114}): 297, frozenset({14}): 69, frozenset({89}): 64, frozenset({143}): 6, frozenset({154}): 151, frozenset({101}): 33, frozenset({129}): 30, frozenset({141}): 15, frozenset({145}): 469, frozenset({13}): 42, frozenset({137}): 280, frozenset({162}): 160, frozenset({70}): 74, frozenset({99}): 42, frozenset({78}): 43, frozenset({52}): 203, frozenset({53}): 81, frozenset({87}): 122, frozenset({139}): 53, frozenset({23}): 36, frozenset({128}): 62, frozenset({95}): 85, frozenset({25}): 80, frozenset({80}): 3, frozenset({153}): 29, frozenset({21}): 48, frozenset({55}): 63, frozenset({103}): 13, frozenset({116}): 11, frozenset({49}): 56, frozenset({86}): 68, frozenset({76}): 21, frozenset({75}): 13, frozenset({43}): 28, frozenset({9}): 77, frozenset({148}): 15, frozenset({158}): 15, frozenset({27}): 24, frozenset({105}): 17, frozenset({41}): 45, frozenset({47}): 17, frozenset({77}): 21, frozenset({3}): 44, frozenset({42}): 43, frozenset({136}): 69, frozenset({11}): 46, frozenset({63}): 21, frozenset({126}): 20, frozenset({85}): 9, frozenset({19}): 13, frozenset({57}): 20, frozenset({88}): 55, frozenset({90}): 56, frozenset({66}): 24, frozenset({37}): 26, frozenset({117}): 23, frozenset({69}): 35, frozenset({152}): 16, frozenset({1}): 21, frozenset({107}): 26, frozenset({115}): 17, frozenset({155}): 2, frozenset({96}): 22, frozenset({94}): 9, frozenset({29}): 12, frozenset({123}): 18, frozenset({122}): 15, frozenset({28}): 15, frozenset({51}): 31, frozenset({38}): 18, frozenset({15}): 14, frozenset({58}): 16, frozenset({91}): 7, frozenset({118}): 13, frozenset({160}): 1, frozenset({6}): 14, frozenset({50}): 21, frozenset({124}): 12, frozenset({74}): 5, frozenset({150}): 14, frozenset({56}): 16, frozenset({62}): 11, frozenset({146}): 3, frozenset({135}): 6, frozenset({119}): 11, frozenset({17}): 3, frozenset({16}): 11, frozenset({2}): 13, frozenset({106}): 9, frozenset({102}): 7, frozenset({157}): 16, frozenset({156}): 7, frozenset({133}): 9, frozenset({24}): 7, frozenset({120}): 4, frozenset({83}): 8, frozenset({109}): 8, frozenset({7}): 3, frozenset({12}): 6, frozenset({71}): 8, frozenset({131}): 6, frozenset({97}): 6, frozenset({79}): 3, frozenset({54}): 2, frozenset({39}): 5, frozenset({59}): 4, frozenset({40}): 1, frozenset({142}): 1, frozenset({73}): 3, frozenset({33}): 1, frozenset({125}): 9, frozenset({110}): 4, frozenset({134}): 1, frozenset({72}): 2, frozenset({140}): 2, frozenset({60}): 5, frozenset({104}): 5, frozenset({8}): 1, frozenset({144}): 1, frozenset({18}): 1}\n"
     ]
    }
   ],
   "source": [
    "# Store all frequent itemsets (keys) with their support (value) in the dictionary below.\n",
    "# TODO: add the length-1 frequent items with their supports to frequent_itemsets (2 points)\n",
    "frequent_itemsets = {}\n",
    "'''\n",
    "Simple way to convert the Counter object to a dictionary with frozenset keys\n",
    "(frozenset is commonly used in association rule mining for apriori algorithm)\n",
    "e.g. https://ethen8181.github.io/machine-learning/association_rule/apriori.html\n",
    "'''\n",
    "for key, value in length1_itemsets.items():\n",
    "        frequent_itemsets[frozenset([key])] = value\n",
    "\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in your findings\n",
    "# https://note.nkmk.me/en/python-key-sort-sorted-max-min/\n",
    "most_frequent_item_id, most_frequent_item_count = max(length1_itemsets.items(), key=lambda x: x[1])\n",
    "most_frequent_item_name = id_to_item[most_frequent_item_id]\n",
    "\n",
    "json_data[\"Task1.2\"][\"most_frequent_item\"] = most_frequent_item_name # e.g. \"birthday cake\" = 1P\n",
    "json_data[\"Task1.2\"][\"len(frequent_itemsets)\"] = len(frequent_itemsets) # how many frequent single itemsets you found = 2P\n",
    "\n",
    "# Then save the file in a separate operation\n",
    "with open(\"submission.json\", \"w\") as f:\n",
    "    json.dump(json_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### B) Determine the frequent n itemsets (15 points)\n",
    "**Task:** Solve the tasks explained in the TODOs and comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: implement the apriori_gen algorithm based on the lecture slides\n",
    "def apriori_gen(itemsets):\n",
    "    # TODO: generate candidates (4 points)\n",
    "    # https://gist.github.com/Stiivi/4730288 (generate_candidates function)\n",
    "    candidates = set()\n",
    "    # Iterate through all pairs of itemsets to generate candidates\n",
    "    for itemset1 in itemsets:\n",
    "        for itemset2 in itemsets:\n",
    "            # Ensure itemsets are of the same length and differ by exactly one item\n",
    "            union = itemset1 | itemset2\n",
    "            # Check if the union is a candidate (i.e., has length + 1)\n",
    "            if (len(union) == len(itemset1) + 1) and (itemset1 != itemset2):\n",
    "                candidates.add(union)\n",
    "\n",
    "    # TODO: prune the candidates and return them (4 points)\n",
    "    # https://towardsdatascience.com/apriori-association-rule-mining-explanation-and-python-implementation-290b42afdfc6/ (pruning function)\n",
    "    pruned_candidates = candidates.copy()\n",
    "    for item in candidates:\n",
    "        # Check if all subsets of the candidate are frequent\n",
    "        is_frequent = True\n",
    "        for subset in itertools.combinations(item, len(item) - 1):\n",
    "            if frozenset(subset) not in itemsets:\n",
    "                is_frequent = False\n",
    "                break\n",
    "        if not is_frequent:\n",
    "            pruned_candidates.remove(item)\n",
    "    return pruned_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: implement an algorithm to calculate the support of the given itemset (2 points)\n",
    "# You do not need to implement a Hash Tree for calculating the supports.\n",
    "# https://towardsdatascience.com/apriori-association-rule-mining-explanation-and-python-implementation-290b42afdfc6/ (getAboveMinSup function)\n",
    "def calculate_support(itemset):\n",
    "    counter = 0\n",
    "    for record in mapped_records:\n",
    "        if itemset.issubset(record):\n",
    "            counter += 1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: set the initial frequent itemsets which needs to be the input of the first iteration (1 point)\n",
    "# (It will be updated at the end of each iteration.)\n",
    "# adapted from https://gist.github.com/Stiivi/4730288\n",
    "\n",
    "frequent_n_itemsets = list(frequent_itemsets.keys())\n",
    "\n",
    "# TODO: set the correct loop condition until the Apriori algorithm should run (1 point)\n",
    "while frequent_n_itemsets:\n",
    "    candidates = apriori_gen(frequent_n_itemsets)\n",
    "    supports = map(calculate_support, candidates)\n",
    "\n",
    "    # TODO: filter out the frequent candidates (2 point)\n",
    "    frequent_candidates = {}\n",
    "    for candidate, support in zip(candidates, supports):\n",
    "        if support >= 11:\n",
    "            frequent_candidates[candidate] = support\n",
    "\n",
    "    # TODO: add the frequent candidates to frequent_itemsets (1 point)\n",
    "    frequent_itemsets.update(frequent_candidates)\n",
    "\n",
    "    # replace the frequent_n_itemsets for the next iteration\n",
    "    frequent_n_itemsets = [itemset for itemset in frequent_candidates]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### C) Save your results (3 points)\n",
    "\n",
    "**Task:** Save all the frequent itemsets along with their absolute supports into a text file named `patterns.txt` and place it in the root of your zip file. Every line corresponds to exactly one frequent itemset and should be in the following format:\n",
    "\n",
    "*support:item1;item2;item3;...*\n",
    "\n",
    "For example, suppose an itemset (whole milk;sausage) has an absolute support 74, then the line corresponding to this frequent itemset in `patterns.txt` should be:\n",
    "\n",
    "*74:whole milk;sausage*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Simple way to write the frequent itemsets to a file separated by semicolons\n",
    "with open(\"patterns.txt\", \"w\") as f:\n",
    "    for itemset, support in frequent_itemsets.items():\n",
    "        # Convert item IDs back to item names\n",
    "        items = [id_to_item[item] for item in sorted(itemset)]\n",
    "        line = f\"{support}:{';'.join(items)}\\n\"\n",
    "        f.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done! You have at correctly formatted 593 patterns.\n"
     ]
    }
   ],
   "source": [
    "def quick_check_patterns():\n",
    "    try:\n",
    "        with open(\"patterns.txt\", 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        if len(lines) < 300:\n",
    "            print(f\"WARNING: Only {len(lines)} lines found. Expected at least 300. There might be a problem with your algorithm.\")\n",
    "        \n",
    "        # Check a few random lines for format\n",
    "        for i in [0, min(10, len(lines)-1), min(100, len(lines)-1)]:\n",
    "            if i < len(lines):\n",
    "                line = lines[i].strip()\n",
    "                if \":\" not in line or line.endswith(\";\") or \",\" in line:\n",
    "                    print(f\"WARNING: Format issue in line {i+1}: {line}\")\n",
    "                    print(\"Expected format: 'support:item1;item2;...' (no trailing semicolon)\")\n",
    "        \n",
    "        print(f\"Well done! You have at correctly formatted {len(lines)} patterns.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"ERROR: patterns.txt file not found! Make sure to save it in the same directory as this jupyter notebook.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR checking file: {str(e)}\")\n",
    "\n",
    "# Run the check\n",
    "quick_check_patterns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1.3 Recommendation (9 points)\n",
    "\n",
    "**Task:** Imagine you're in a small local grocery shop. You want to put items that are bought together frequently in close proximity.\n",
    "Let's assume there are two customers: Gustave and Lune. Gustave has \"pastry\" and \"soda\" in his basket and Lune has a \"sausage\" in her basket. Give an item recommendation for each customer by maximizing the confidence that the user will also purchase the recommended item. (9 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation for Gustave: whole milk (confidence: 0.4375)\n",
      "Recommendation for Lune: whole milk (confidence: 0.2727)\n"
     ]
    }
   ],
   "source": [
    "def recommend_item(basket, frequent_itemsets):\n",
    "    basket_set = frozenset(basket)\n",
    "    basket_support = frequent_itemsets.get(basket_set, 0)\n",
    "\n",
    "    best_item = None\n",
    "    best_conf = 0\n",
    "\n",
    "    if basket_support > 0:\n",
    "        for itemset, support in frequent_itemsets.items():\n",
    "            if basket_set < itemset and len(itemset - basket_set) == 1:\n",
    "                new_item = next(iter(itemset - basket_set))\n",
    "                conf = support / basket_support\n",
    "                if conf > best_conf:\n",
    "                    best_conf = conf\n",
    "                    best_item = new_item\n",
    "\n",
    "    return best_item, best_conf\n",
    "\n",
    "\n",
    "\n",
    "gustave_basket = [\"pastry\", \"soda\"]\n",
    "gustave_ids = [item_to_id[item] for item in gustave_basket]\n",
    "\n",
    "lune_basket = [\"sausage\"]\n",
    "lune_ids = [item_to_id[item] for item in lune_basket]\n",
    "\n",
    "gustave_rec, gustave_conf = recommend_item(gustave_ids, frequent_itemsets)\n",
    "lune_rec, lune_conf = recommend_item(lune_ids, frequent_itemsets)\n",
    "\n",
    "if gustave_rec is not None:\n",
    "    print(f\"Recommendation for Gustave: {id_to_item[gustave_rec]} (confidence: {gustave_conf:.4f})\")\n",
    "else:\n",
    "    print(\"No recommendation for Gustave.\")\n",
    "\n",
    "if lune_rec is not None:\n",
    "    print(f\"Recommendation for Lune: {id_to_item[lune_rec]} (confidence: {lune_conf:.4f})\")\n",
    "else:\n",
    "    print(\"No recommendation for Lune.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 1.2\n",
    "json_data[\"Task1.3\"][\"recommendation_for_pastry_and_soda\"] = id_to_item[gustave_rec] # e.g. \"easter egg\" = 2P\n",
    "json_data[\"Task1.3\"][\"confidence_for_recommendation_for_pastry_and_soda\"] = round(gustave_conf, 4) # with 4 decimal points e.g. 0.1234 = 1P\n",
    "json_data[\"Task1.3\"][\"recommendations_for_sausage\"] = id_to_item[lune_rec] # e.g. [\"easter egg\", \"chocolate\"] = 3P\n",
    "json_data[\"Task1.3\"][\"confidences_for_recommendations_for_sausage\"] = round(lune_conf, 4) # with 4 decimal points e.g. [0.1234, 0.5678] = 3P\n",
    "\n",
    "# Then save the file in a separate operation\n",
    "with open(\"submission.json\", \"w\") as f:\n",
    "    json.dump(json_data, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
